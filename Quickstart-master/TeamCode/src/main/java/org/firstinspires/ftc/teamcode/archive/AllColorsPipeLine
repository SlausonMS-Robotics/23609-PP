import cv2
import numpy as np

# Called once per frame
def runPipeline(image, llrobot):
    # ----- Color thresholding (tune for your lighting) -----
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

    lower_red1, upper_red1 = (0, 100, 100), (10, 255, 255)
    lower_red2, upper_red2 = (160, 100, 100), (179, 255, 255)
    lower_yel,  upper_yel  = (20, 120, 120), (35, 255, 255)
    lower_blu,  upper_blu  = (90, 120, 120), (120, 255, 255)

    mask_red = cv2.bitwise_or(
        cv2.inRange(hsv, lower_red1, upper_red1),
        cv2.inRange(hsv, lower_red2, upper_red2)
    )
    mask_yel = cv2.inRange(hsv, lower_yel, upper_yel)
    mask_blu = cv2.inRange(hsv, lower_blu, upper_blu)

    # (optional) quick cleanup to reduce speckle
    kernel = np.ones((3,3), np.uint8)
    mask_red = cv2.morphologyEx(mask_red, cv2.MORPH_OPEN, kernel, iterations=1)
    mask_yel = cv2.morphologyEx(mask_yel, cv2.MORPH_OPEN, kernel, iterations=1)
    mask_blu = cv2.morphologyEx(mask_blu, cv2.MORPH_OPEN, kernel, iterations=1)

    color_masks = [("red", mask_red), ("yellow", mask_yel), ("blue", mask_blu)]

    # Camera FOVs (degrees). Adjust after calibration.
    HFOV = 59.6
    VFOV = 45.7

    h, w = image.shape[:2]
    outputs = []
    chosen_contour = np.array([[]])

    def push_det(cx, cy, area, class_id):
        xDeg = (cx - (w / 2)) * (HFOV / w)
        yDeg = (cy - (h / 2)) * (VFOV / h)
        # Output 6-tuple per detection:
        # [xDeg, yDeg, area, class_id, cx, cy]
        return [xDeg, yDeg, area, class_id, int(cx), int(cy)]

    for color, mask in color_masks:
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not contours:
            continue

        # You can choose largest or loop all; weâ€™ll loop all contours for that color
        for c in contours:
            area = float(cv2.contourArea(c))
            if area <= 100:  # noise filter; tune as needed
                continue
            M = cv2.moments(c)
            if M["m00"] <= 0:
                continue
            cx = M["m10"] / M["m00"]
            cy = M["m01"] / M["m00"]

            class_id = 0 if color == "red" else 1 if color == "yellow" else 2
            outputs.extend(push_det(cx, cy, area, class_id))

            # choose the largest contour overall for crosshair/overlay
            if chosen_contour.size == 0 or area > cv2.contourArea(chosen_contour):
                chosen_contour = c

            # (optional) draw for debugging
            cv2.drawContours(image, [c], -1, (255, 255, 255), 1)
            cv2.circle(image, (int(cx), int(cy)), 5, (255, 255, 255), 2)
            cv2.putText(image, color, (int(cx)+4, int(cy)-4),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)

    llpython = outputs  # 6 values per detection; may be empty
    return chosen_contour, image, llpython
